environment: "test"

app:
  name: app
  group: app
  replicaCount: 1
  container:
    image: adriangb/otel-test
    tag: latest
    port: 8000
    config: []
  service:
    type: ClusterIP
    port: 8000

serviceAccountRBAC:
  enabled: true
  clusterRoleRules:
    - apiGroups:
      - ""
      resources:
      - events
      - namespaces
      - namespaces/status
      - nodes
      - nodes/spec
      - pods
      - pods/metrics
      - nodes/metrics
      - pods/status
      - replicationcontrollers
      - replicationcontrollers/status
      - resourcequotas
      - services
      - endpoints
      verbs:
      - get
      - list
      - watch

opentelemetry-collector:
  fullnameOverride: "opentelemetry-collector"
  image:
    repository: otel/opentelemetry-collector-contrib
    pullPolicy: IfNotPresent
    tag: "0.30.0"

  command:
    name: otelcontribcol

  agentCollector:
    enabled: true

    configOverride:
      receivers:
        otlp:
          protocols:
            grpc:
            http:
      processors:
        batch:
        # The resource detector injects the pod IP
        # to every trace so that the k8s_tagger can
        # fetch information afterwards.
        resourcedetection:
          detectors: [env]
          timeout: 5s
          override: false
        # The k8s_tagger in the Agent is in passthrough mode
        # so that it only tags with the minimal info for the
        # collector k8s_tagger to complete
        k8s_tagger:
          passthrough: true
        memory_limiter:
          check_interval: 5s
          limit_percentage: 50
          spike_limit_percentage: 30
      extensions:
        health_check: {}
      exporters:
        otlp:
          endpoint: "opentelemetry-collector:4317"
          insecure: true
      service:
        extensions: [health_check]
        pipelines:
          traces:
            receivers: [otlp]
            # resourcedetection must come before k8s_tagger
            processors: [memory_limiter, resourcedetection, k8s_tagger, batch]
            exporters: [otlp]

    resources:
      limits:
        cpu: 500m
        memory: 1024Mi
      requests:
        cpu: 200m
        memory: 200Mi
    
    extraEnvs:
      - name: MY_POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP

  standaloneCollector:
    enabled: true

    configOverride:
      receivers:
        otlp:
          protocols:
            grpc:
            http:
      processors:
        batch:
          timeout: 10s
        k8s_tagger:
          passthrough: false
          extract:
            metadata:
              # extract the following well-known metadata fields from pods and namespaces
              - k8s.pod.name
              - k8s.pod.uid
              - k8s.deployment.name
              - k8s.cluster.name
              - k8s.namespace.name
              - k8s.node.name
              - k8s.pod.start_time
            annotations:
              - tag_name: service.name123
                key: opentelemetry.io/service.name
                from: pod
              - tag_name: service.version
                key: opentelemetry.io/service.version
                from: pod
              - tag_name: deployment.environment
                key: opentelemetry.io/deployment.environment
                from: pod
          pod_association:
            - from: resource_attribute
              name: k8s.pod.ip
      extensions:
        health_check: {}
      exporters:
        logging/debug:
          loglevel: debug
        logging/error:
          loglevel: error
      service:
        extensions: [health_check]
        pipelines:
          traces:
            receivers: [otlp]
            processors: [k8s_tagger, batch]
            exporters: [logging/debug]
          metrics:
            receivers: [otlp]
            processors: [k8s_tagger, batch]
            exporters: [logging/error]

    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 200Mi

    ports:
      otlp:
        enabled: true
        containerPort: 4317
        servicePort: 4317
        hostPort: 4317
        protocol: TCP
      jaeger-thrift:
        enabled: false
      jaeger-grpc:
        enabled: false
      zipkin:
        enabled: false

  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 4
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 80
